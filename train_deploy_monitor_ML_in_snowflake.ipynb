{
 "metadata": {
  "kernelspec": {
   "display_name": "Python37 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lastEditStatus": {
   "notebookId": "ko7qqebc5tlvqrvwau7i",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "2022b27f-5bbc-427f-9b4c-0ae6c1ad8ea2",
   "lastEditTime": 1744234615667
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ae8e5-aec2-4276-9443-074c3a614142",
   "metadata": {
    "name": "INTRO_MD",
    "collapsed": false
   },
   "source": "# ❄️ End-to-end ML Demo ❄️\n\nIn this worfklow we will work through the following elements of a typical tabular machine learning pipeline.\n\n### 1. Use Feature Store to track engineered features\n* Store feature defintions in feature store for reproducible computation of ML features\n      \n### 2. Train two Models using the Snowflake ML APIs\n* Baseline XGboost\n* XGboost with optimal hyper-parameters identified via Snowflake ML distributed HPO methods\n\n### 3. Register both models in Snowflake model registry\n* Explore model registry capabilities such as **metadata tracking, inference, and explainability**\n* Compare model metrics on train/test set to identify any issues of model performance or overfitting\n* Tag the best performing model version as 'default' version\n### 4. Set up Model Monitor to track 1 year of predicted and actual loan repayments\n* **Compute performance metrics** such a F1, Precision, Recall\n* **Inspect model drift** (i.e. how much has the average predicted repayment rate changed day-to-day)\n* **Compare models** side-by-side to understand which model should be used in production\n* Identify and understand **data issues**\n\n### 5. Track data and model lineage throughout\n* View and understand\n  * The **origin of the data** used for computed features\n  * The **data used** for model training\n  * The **available model versions** being monitored"
  },
  {
   "cell_type": "code",
   "id": "a2512cb5-15ae-40b2-84c7-8a44a9979670",
   "metadata": {
    "language": "python",
    "name": "pip_installs",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip install shap",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d78265b8-8baa-4136-a32a-32f3f620949d",
   "metadata": {
    "language": "python",
    "name": "set_version_num_and_vars",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "#Update this VERSION_NUM to version your features, models etc!\nVERSION_NUM = '0'\nDB = \"E2E_SNOW_MLOPS_DB\" \nSCHEMA = \"MLOPS_SCHEMA\" \nCOMPUTE_WAREHOUSE = \"E2E_SNOW_MLOPS_WH\" ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "name": "imports_and_session",
    "language": "python",
    "collapsed": false,
    "resultHeight": 84,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport sklearn\nimport math\nimport pickle\nimport shap\nfrom datetime import datetime\nimport streamlit as st\nfrom xgboost import XGBClassifier\n\n# Snowpark ML\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\n\n#Snowflake feature store\nfrom snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n\n# Snowpark session\nfrom snowflake.snowpark import DataFrame\nfrom snowflake.snowpark.functions import col, to_timestamp, min, max, month, dayofweek, dayofyear, avg, date_add, sql_expr\nfrom snowflake.snowpark.types import IntegerType\nfrom snowflake.snowpark import Window\n\n#setup snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nsession",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "code",
   "id": "f8900d1d-a1f2-419b-ae7e-b194f268d904",
   "metadata": {
    "language": "python",
    "name": "read_raw_data",
    "resultHeight": 223,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "try:\n    print(\"Reading table data...\")\n    df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n    df.show(5)\nexcept:\n    print(\"Table not found! Uploading data to snowflake table\")\n    df_pandas = pd.read_csv(\"MORTGAGE_LENDING_DEMO_DATA.csv.zip\")\n    session.write_pandas(df_pandas, \"MORTGAGE_LENDING_DEMO_DATA\", auto_create_table=True)\n    df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n    df.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60938b6f-bda7-4783-ae44-547bd34d98de",
   "metadata": {
    "name": "md1",
    "collapsed": false
   },
   "source": "## Observe Snowflake Snowpark table properties"
  },
  {
   "cell_type": "code",
   "id": "a6654de7-6407-4ffe-a214-fd66078397ef",
   "metadata": {
    "language": "python",
    "name": "see_timespan",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df.select(min('TS'), max('TS'))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b5a38cc-c479-4839-b0ae-9e5cb3e0facb",
   "metadata": {
    "language": "python",
    "name": "find_timedelta",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Get current date and time\ncurrent_time = datetime.now()\ndf_max_time = datetime.strptime(str(df.select(max(\"TS\")).collect()[0][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n\n#Find delta between latest existing timestamp and today's date\ntimedelta = current_time- df_max_time\n\n#Update timestamps to represent last ~1 year from today's date\ndf.select(min(date_add(to_timestamp(\"TS\"), timedelta.days-1)), max(date_add(to_timestamp(\"TS\"), timedelta.days-1)))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8aa46c7d-519b-422c-8932-9b031fc6b4bd",
   "metadata": {
    "name": "feat_eng_md",
    "collapsed": false
   },
   "source": "## Feature Engineering with Snowpark APIs"
  },
  {
   "cell_type": "code",
   "id": "b355c0c4-9dc6-4faf-86b7-24d8d559e453",
   "metadata": {
    "language": "python",
    "name": "define_features",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create a dict with keys for feature names and values containing transform code\n\nfeature_eng_dict = dict()\n\n#Timstamp features\nfeature_eng_dict[\"TIMESTAMP\"] = date_add(to_timestamp(\"TS\"), timedelta.days-1)\nfeature_eng_dict[\"MONTH\"] = month(\"TIMESTAMP\")\nfeature_eng_dict[\"DAY_OF_YEAR\"] = dayofyear(\"TIMESTAMP\") \nfeature_eng_dict[\"DOTW\"] = dayofweek(\"TIMESTAMP\")\n\n# df= df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\n\n#Income and loan features\nfeature_eng_dict[\"LOAN_AMOUNT\"] = col(\"LOAN_AMOUNT_000s\")*1000\nfeature_eng_dict[\"INCOME\"] = col(\"APPLICANT_INCOME_000s\")*1000\nfeature_eng_dict[\"INCOME_LOAN_RATIO\"] = col(\"INCOME\")/col(\"LOAN_AMOUNT\")\n\ncounty_window_spec = Window.partition_by(\"COUNTY_NAME\")\nfeature_eng_dict[\"MEAN_COUNTY_INCOME\"] = avg(\"INCOME\").over(county_window_spec)\nfeature_eng_dict[\"HIGH_INCOME_FLAG\"] = (col(\"INCOME\")>col(\"MEAN_COUNTY_INCOME\")).astype(IntegerType())\n\nfeature_eng_dict[\"AVG_THIRTY_DAY_LOAN_AMOUNT\"] =  sql_expr(\"\"\"AVG(LOAN_AMOUNT) OVER (PARTITION BY COUNTY_NAME ORDER BY TIMESTAMP  \n                                                            RANGE BETWEEN INTERVAL '30 DAYS' PRECEDING AND CURRENT ROW)\"\"\")\n\ndf = df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\ndf.show(3)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6c4ead8-25ac-46cc-9bd9-17eac2f796d5",
   "metadata": {
    "language": "python",
    "name": "df_explain",
    "resultHeight": 312,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df.explain()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72d7645e-e0ac-4539-b132-54ce53431402",
   "metadata": {
    "name": "feature_store_markdown",
    "collapsed": false
   },
   "source": "## Create a Snowflake Feature Store"
  },
  {
   "cell_type": "code",
   "id": "abacdc71-9f2c-419f-8d50-3e8f89be367f",
   "metadata": {
    "language": "python",
    "name": "define_feature_store",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fs = FeatureStore(\n    session=session, \n    database=DB, \n    name=SCHEMA, \n    default_warehouse=COMPUTE_WAREHOUSE,\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67480d6a-183f-4373-aaa8-d3ed8e80e11d",
   "metadata": {
    "language": "python",
    "name": "list_entities",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fs.list_entities()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d915406f-e52d-4baf-9f6c-b9e0e8d53e6e",
   "metadata": {
    "name": "FS_CONFIG_MD",
    "collapsed": false
   },
   "source": "## Feature Store configuration\n- create/register entities of interest"
  },
  {
   "cell_type": "code",
   "id": "e91d6d39-7819-4825-8729-a3f19ca5cdf7",
   "metadata": {
    "language": "python",
    "name": "load_or_register_entity",
    "resultHeight": 38,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#First try to retrieve an existing entity definition, if not define a new one and register\ntry:\n    #retrieve existing entity\n    loan_id_entity = fs.get_entity('LOAN_ENTITY') \n    print('Retrieved existing entity')\nexcept:\n#define new entity\n    loan_id_entity = Entity(\n        name = \"LOAN_ENTITY\",\n        join_keys = [\"LOAN_ID\"],\n        desc = \"Features defined on a per loan level\")\n    #register\n    fs.register_entity(loan_id_entity)\n    print(\"Registered new entity\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2820463f-0ea7-43ea-a500-9b034011887d",
   "metadata": {
    "language": "python",
    "name": "create_feature_df",
    "resultHeight": 217,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create a dataframe with just the ID, timestamp, and engineered features. We will use this to define our feature view\nfeature_df = df.select([\"LOAN_ID\"]+list(feature_eng_dict.keys()))\nfeature_df.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5cf84fe3-4120-4092-b43d-8873da57d461",
   "metadata": {
    "name": "FS_MD",
    "collapsed": false
   },
   "source": "Here, the feature store references an existing table. \n\nWe could also define the dataframe via the use of Snowpark APIs, and use that dataframe (or a function that returns a dataframe) as the feature view definition, below."
  },
  {
   "cell_type": "code",
   "id": "2b53364f-90c4-45b4-94ee-b2fde6f93475",
   "metadata": {
    "language": "python",
    "name": "feature_veiw_creation",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#define and register feature view\nloan_fv = FeatureView(\n    name=\"Mortgage_Feature_View\",\n    entities=[loan_id_entity],\n    feature_df=feature_df,\n    timestamp_col=\"TIMESTAMP\",\n    refresh_freq=\"1 day\")\n\n#add feature level descriptions\n\nloan_fv = loan_fv.attach_feature_desc(\n    {\n        \"MONTH\": \"Month of loan\",\n        \"DAY_OF_YEAR\": \"Day of calendar year of loan\",\n        \"DOTW\": \"Day of the week of loan\",\n        \"LOAN_AMOUNT\": \"Loan amount in $USD\",\n        \"INCOME\": \"Household income in $USD\",\n        \"INCOME_LOAN_RATIO\": \"Ratio of LOAN_AMOUNT/INCOME\",\n        \"MEAN_COUNTY_INCOME\": \"Average household income aggregated at county level\",\n        \"HIGH_INCOME_FLAG\": \"Binary flag to indicate whether household income is higher than MEAN_COUNTY_INCOME\",\n        \"AVG_THIRTY_DAY_LOAN_AMOUNT\": \"Rolling 30 day average of LOAN_AMOUNT\"\n    }\n)\n\nloan_fv = fs.register_feature_view(loan_fv, version=VERSION_NUM, overwrite=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18c3225b-b936-4aa7-81f2-27bbaeee1c0f",
   "metadata": {
    "language": "python",
    "name": "show_feature_views",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fs.list_feature_views()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f7a1aae-0bd2-4aad-b9ed-3347fc56b6ea",
   "metadata": {
    "language": "python",
    "name": "create_feature_store_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create link to feature store UI to inspect newly created feature view!\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/features/database/{DB}/store/{SCHEMA}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e96ff67f-bb04-40cb-8c14-11b5ebb2917d",
   "metadata": {
    "name": "FV_MD",
    "collapsed": false
   },
   "source": "## Retrieve a Dataset from the featureview\n\nSnowflake Datasets are immutable, file-based objects that exist within your Snowpark session. \n\nThey can be written to persistent Snowflake objects as needed. "
  },
  {
   "cell_type": "code",
   "id": "535efc80-e4fc-41c5-98eb-5b5450bcf199",
   "metadata": {
    "language": "python",
    "name": "generate_dataset",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ds = fs.generate_dataset(\n    name=f\"MORTGAGE_DATASET_EXTENDED_FEATURES_{VERSION_NUM}\",\n    spine_df=df.select(\"LOAN_ID\", \"TIMESTAMP\", \"LOAN_PURPOSE_NAME\",\"MORTGAGERESPONSE\"), #only need the features used to fetch rest of feature view\n    features=[loan_fv],\n    spine_timestamp_col=\"TIMESTAMP\",\n    spine_label_cols=[\"MORTGAGERESPONSE\"]\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ecdaa537-3fb9-476c-9153-3236edfdfcb3",
   "metadata": {
    "language": "python",
    "name": "convert_dataset_to_snowpark_and_pandas",
    "resultHeight": 239,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ds_sp = ds.read.to_snowpark_dataframe()\nds_sp.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5e17036-7a69-4915-b025-49c900aeb46b",
   "metadata": {
    "language": "python",
    "name": "one_hot_encoding",
    "collapsed": false,
    "resultHeight": 360,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import snowflake.ml.modeling.preprocessing as snowml\nfrom snowflake.snowpark.types import StringType\n\nOHE_COLS = ds_sp.select([col.name for col in ds_sp.schema if col.datatype ==StringType()]).columns\nOHE_POST_COLS = [i+\"_OHE\" for i in OHE_COLS]\n\n\n# Encode categoricals to numeric columns\nsnowml_ohe = snowml.OneHotEncoder(input_cols=OHE_COLS, output_cols = OHE_COLS, drop_input_cols=True)\nds_sp_ohe = snowml_ohe.fit(ds_sp).transform(ds_sp)\n\n#Rename columns to avoid double nested quotes and white space chars\nrename_dict = {}\nfor i in ds_sp_ohe.columns:\n    if '\"' in i:\n        rename_dict[i] = i.replace('\"','').replace(' ', '_')\n\nds_sp_ohe = ds_sp_ohe.rename(rename_dict)\nds_sp_ohe.columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d834f6f3-ce15-405e-8fec-1d1bb5c224a6",
   "metadata": {
    "language": "python",
    "name": "train_test_split",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "train, test = ds_sp_ohe.random_split(weights=[0.70, 0.30], seed=0)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8ff103e-5314-4e95-87ba-d784b1102f36",
   "metadata": {
    "language": "python",
    "name": "fill_na",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "train = train.fillna(0)\ntest = test.fillna(0)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c917df7f-e277-4fbb-abf5-1a4433367e3b",
   "metadata": {
    "language": "python",
    "name": "convert_data_to_pandas",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "train_pd = train.to_pandas()\ntest_pd = test.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38c05dc9-2efb-4c5f-995a-486ef926c6c5",
   "metadata": {
    "name": "model_training_md",
    "collapsed": false
   },
   "source": "## Model Training\n### Below we will define and fit an xgboost classifier as our baseline model and evaluate the performance\n##### Note this is all done with OSS frameworks"
  },
  {
   "cell_type": "code",
   "id": "5e4b5fba-b7a8-47ff-aaf6-076b9e78dcaf",
   "metadata": {
    "language": "python",
    "name": "define_model",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Define model config\nxgb_base = XGBClassifier(\n    max_depth=50,\n    n_estimators=3,\n    learning_rate = 0.75,\n    booster = 'gbtree')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "644f3295-2496-4fd0-ae95-922a78c5b944",
   "metadata": {
    "language": "python",
    "name": "train_base_model",
    "resultHeight": 1759,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Split train data into X, y\nX_train_pd = train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1) #remove\ny_train_pd = train_pd.MORTGAGERESPONSE\n\n#train model\nxgb_base.fit(X_train_pd,y_train_pd)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c5ac861-fcf9-47b2-9c11-ec44ee2367e4",
   "metadata": {
    "language": "python",
    "name": "compute_predictions_and_perf_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.metrics import f1_score, precision_score, recall_score\ntrain_preds_base = xgb_base.predict(X_train_pd) #update this line with correct ata\n\nf1_base_train = round(f1_score(y_train_pd, train_preds_base),4)\nprecision_base_train = round(precision_score(y_train_pd, train_preds_base),4)\nrecall_base_train = round(recall_score(y_train_pd, train_preds_base),4)\n\nprint(f'F1: {f1_base_train} \\nPrecision {precision_base_train} \\nRecall: {recall_base_train}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93777778-d2ba-42d5-88c4-a90ba18c5006",
   "metadata": {
    "name": "model_regisry_md",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Model Registry\n\n- Log models with important metadata\n- Manage model lifecycles\n- Serve models from Snowflake runtimes"
  },
  {
   "cell_type": "code",
   "id": "21678e59-deaf-4c2b-b01e-1c59fe31b10a",
   "metadata": {
    "language": "python",
    "name": "define_model_registry",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create a snowflake model registry object \nfrom snowflake.ml.registry import Registry\n\n# Define model name\nmodel_name = f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\"\n\n# Create a registry to log the model to\nmodel_registry = Registry(session=session, \n                          database_name=DB, \n                          schema_name=SCHEMA,\n                          options={\"enable_monitoring\": True})",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be41c3ac-49f0-4fd9-a557-9d8eb633f602",
   "metadata": {
    "language": "python",
    "name": "register_model_version",
    "collapsed": false,
    "resultHeight": 229,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Deploy the base model to the model registry\nbase_version_name = 'XGB_BASE'\n\ntry:\n    mv_base = model_registry.get_model(model_name).version(base_version_name)\n    print(\"Found existing model version!\")\nexcept:\n    print(\"Logging new model version...\")\n    mv_base = model_registry.log_model(\n        model_name=model_name,\n        model=xgb_base, \n        version_name=base_version_name,\n        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n        comment = \"\"\"ML model for predicting loan approval likelihood.\n                    This model was trained using  xgboost classifier.\n                    Hyperparameters used were:a\n                    max_depth=50, n_estimators=3, learning_rate = 0.75, algorithm = gbtree.\n                    \"\"\",\n    )\n    mv_base.set_metric(metric_name=\"Train_F1_Score\", value=f1_base_train)\n    mv_base.set_metric(metric_name=\"Train_Precision_Score\", value=precision_base_train)\n    mv_base.set_metric(metric_name=\"Train_Recall_score\", value=recall_base_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68e2ddab-b02a-4e05-8121-4e97e49e0eea",
   "metadata": {
    "language": "python",
    "name": "create_prod_tag",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create tag for PROD model\nsession.sql(\"CREATE OR REPLACE TAG PROD\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e0054df-0cd9-4e81-98b8-6564be86b4b9",
   "metadata": {
    "language": "python",
    "name": "create_PROD_tag",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Apply prod tag \nm = model_registry.get_model(model_name)\nm.comment = \"Loan approval prediction models\" #set model level comment\nm.set_tag(\"PROD\", base_version_name)\nm.show_tags()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac4e294e-929d-4399-b2bb-d5d2d1dd043e",
   "metadata": {
    "language": "python",
    "name": "show_models",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model_registry.show_models()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3dfb281-9751-48a1-a76e-43ffffd9d099",
   "metadata": {
    "language": "python",
    "name": "show_model_versions",
    "resultHeight": 146,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model_registry.get_model(model_name).show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb1af8a1-7a92-455e-b9a1-8f2c699dfdeb",
   "metadata": {
    "language": "python",
    "name": "print_model_version_and_metrics",
    "resultHeight": 239,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "print(mv_base)\nprint(mv_base.show_metrics())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ecdf05c-b3b5-4755-bdff-fd187ef07f58",
   "metadata": {
    "language": "python",
    "name": "show_model_functions",
    "resultHeight": 2133,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mv_base.show_functions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf495261-a8a7-46be-b9c8-3f099268d154",
   "metadata": {
    "language": "python",
    "name": "predict_from_registry",
    "resultHeight": 351,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "reg_preds = mv_base.run(test, function_name = \"predict\").rename(col('\"output_feature_0\"'), \"MORTGAGE_PREDICTION\")\nreg_preds.show(10)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ef61447-10e7-4a38-a429-3da3facf9ce7",
   "metadata": {
    "language": "python",
    "name": "compute_test_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#ds_sp_ohe = ds_sp_ohe.rename(col('\"LOAN_PURPOSE_NAME_Home improvement\"'), \"LOAN_PURPOSE_NAME_Home_improvement\")\n\npreds_pd = reg_preds.select([\"MORTGAGERESPONSE\", \"MORTGAGE_PREDICTION\"]).to_pandas()\nf1_base_test = round(f1_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\nprecision_base_test = round(precision_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\nrecall_base_test = round(recall_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n\n#log metrics to model registry model\nmv_base.set_metric(metric_name=\"Test_F1_Score\", value=f1_base_test)\nmv_base.set_metric(metric_name=\"Test_Precision_Score\", value=precision_base_test)\nmv_base.set_metric(metric_name=\"Test_Recall_score\", value=recall_base_test)\n\nprint(f'F1: {f1_base_test} \\nPrecision {precision_base_test} \\nRecall: {recall_base_test}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9b477885-35ce-486d-9e86-7d0cc9d48454",
   "metadata": {
    "name": "HPO_MD",
    "collapsed": false
   },
   "source": "# Oh no! Our model's performance seems to have dropped off significantly from training to our test set. \n## This is evidence that our model is overfit - can we fix this with Distributed Hyperparameter Optimization??"
  },
  {
   "cell_type": "code",
   "id": "c47e068d-7e1d-4c74-8289-d03ea8ab3c7e",
   "metadata": {
    "language": "python",
    "name": "setup_x_and_y",
    "collapsed": false
   },
   "outputs": [],
   "source": "X_train = train.drop(\"MORTGAGERESPONSE\", \"TIMESTAMP\", \"LOAN_ID\")\ny_train = train.select(\"MORTGAGERESPONSE\")\nX_test = test.drop(\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\")\ny_test = test.select(\"MORTGAGERESPONSE\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fff76e05-38f5-47cf-ab5d-9eefed09bd71",
   "metadata": {
    "language": "python",
    "name": "define_HPO_config",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.data import DataConnector\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\n\n#Define dataset map\ndataset_map = {\n    \"x_train\": DataConnector.from_dataframe(X_train),\n    \"y_train\": DataConnector.from_dataframe(y_train),\n    \"x_test\": DataConnector.from_dataframe(X_test),\n    \"y_test\": DataConnector.from_dataframe(y_test)\n    }\n\n\n# Define a training function, with any models you choose within it.\ndef train_func():\n    # A context object provided by HPO API to expose data for the current HPO trial\n    tuner_context = get_tuner_context()\n    config = tuner_context.get_hyper_params()\n    dm = tuner_context.get_dataset_map()\n\n    model = XGBClassifier(**config, random_state=42)\n    model.fit(dm[\"x_train\"].to_pandas().sort_index(), dm[\"y_train\"].to_pandas().sort_index())\n    f1_metric = f1_score(\n        dm[\"y_train\"].to_pandas().sort_index(), model.predict(dm[\"x_train\"].to_pandas().sort_index())\n    )\n    tuner_context.report(metrics={\"f1_score\": f1_metric}, model=model)\n\ntuner = tune.Tuner(\n    train_func=train_func,\n    search_space={\n        \"max_depth\": tune.randint(1, 10),\n        \"learning_rate\": tune.uniform(0.01, 0.1),\n        \"n_estimators\": tune.randint(50, 100),\n    },\n    tuner_config=tune.TunerConfig(\n        metric=\"f1_score\",\n        mode=\"max\",\n        search_alg=search_algorithm.RandomSearch(random_state=101),\n        num_trials=8, #run 8 trial runs\n        max_concurrent_trials=4, #run 8 trials at a time\n    ),\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14b88e99-9d2a-44cd-81f9-d53fd1321daf",
   "metadata": {
    "language": "python",
    "name": "run_hpo",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Train several model candidates (note this may take 1-2 minutes)\ntuner_results = tuner.run(dataset_map=dataset_map)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ee37c42-3de7-476a-b7c0-d56952dac385",
   "metadata": {
    "language": "python",
    "name": "inspect_hpo_params",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "#Select best model results and inspect configuration\ntuned_model = tuner_results.best_model\ntuned_model",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94b4a6c2-674e-4d02-afdb-8ebf10cffdc4",
   "metadata": {
    "language": "python",
    "name": "compute_hpo_train_predictions_and_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Generate predictions\nxgb_opt_preds = tuned_model.predict(train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n\n#Generate performance metrics\nf1_opt_train = round(f1_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\nprecision_opt_train = round(precision_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\nrecall_opt_train = round(recall_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n\nprint(f'Train Results: \\nF1: {f1_opt_train} \\nPrecision {precision_opt_train} \\nRecall: {recall_opt_train}')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dee80c48-d521-4b77-8841-54ba35ecd4b6",
   "metadata": {
    "language": "python",
    "name": "compute_hpo_test_predictions_and_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Generate test predictions\nxgb_opt_preds_test = tuned_model.predict(test_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n\n#Generate performance metrics on test data\nf1_opt_test = round(f1_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\nprecision_opt_test = round(precision_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\nrecall_opt_test = round(recall_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n\nprint(f'Test Results: \\nF1: {f1_opt_test} \\nPrecision {precision_opt_test} \\nRecall: {recall_opt_test}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89a1a670-52e3-4d77-ac3a-db830e22fdcf",
   "metadata": {
    "name": "HPO_performance_reaction",
    "collapsed": false
   },
   "source": "# Here we see the HPO model has a more modest train accuracy than our base model - but the peformance doesn't drop off during testing"
  },
  {
   "cell_type": "code",
   "id": "d501cf7d-4965-4b9f-8b16-edab897d0e18",
   "metadata": {
    "language": "python",
    "name": "log_hpo_model",
    "collapsed": false
   },
   "outputs": [],
   "source": "#Log the optimized model to the model registry\noptimized_version_name = 'XGB_Optimized'\n\ntry:\n    mv_opt = model_registry.get_model(model_name).version(optimized_version_name)\n    print(\"Found existing model version!\")\nexcept:\n    print(\"Logging new model version...\")\n    mv_opt = model_registry.log_model(\n        model_name=model_name,\n        model=tuned_model, \n        version_name=optimized_version_name,\n        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100),\n        comment = \"snow ml model built off feature store using HPO model\",\n    )\n    mv_opt.set_metric(metric_name=\"Train_F1_Score\", value=f1_opt_train)\n    mv_opt.set_metric(metric_name=\"Train_Precision_Score\", value=precision_opt_train)\n    mv_opt.set_metric(metric_name=\"Train_Recall_score\", value=recall_opt_train)\n\n    mv_opt.set_metric(metric_name=\"Test_F1_Score\", value=f1_opt_test)\n    mv_opt.set_metric(metric_name=\"Test_Precision_Score\", value=precision_opt_test)\n    mv_opt.set_metric(metric_name=\"Test_Recall_score\", value=recall_opt_test)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4c028b9-b590-45b4-9884-35ee206bca0d",
   "metadata": {
    "language": "python",
    "name": "inspect_current_default_version",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Here we see the BASE version is our default version\nmodel_registry.get_model(model_name).default",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04ac97a9-7af4-4331-bb0d-cf6ecc4a77f6",
   "metadata": {
    "language": "python",
    "name": "promote_optimized_version_to_default",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Now we'll set the optimized model to be the default model version going forward\nmodel_registry.get_model(model_name).default = optimized_version_name",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c04efcee-27e6-4423-b669-849bec7cc8fb",
   "metadata": {
    "language": "python",
    "name": "see_updated_model_versions",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Now we see our optimized version we have now recently promoted to our DEFAULT model version\nmodel_registry.get_model(model_name).default",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8cc92f7f-5f02-4cc5-82d0-758f65f2d485",
   "metadata": {
    "language": "python",
    "name": "update_model_tags",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#we'll now update the PROD tagged model to be the optimized model version rather than our overfit base version\nm.unset_tag(\"PROD\")\nm.set_tag(\"PROD\", optimized_version_name)\nm.show_tags()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05fff15e-5f49-4d4f-a02a-93e8f3114b11",
   "metadata": {
    "name": "explainability_MD",
    "collapsed": false
   },
   "source": "## Now that we've deployed some model versions and tested inference... \n# Let's explain our models!\n- ### Snowflake offers built in explainability capabilities on top of models logged to the model registry\n- ### In the below section we'll generate shapley values using these built in functions to understand how input features impact our model's behavior"
  },
  {
   "cell_type": "code",
   "id": "914f5cd6-d254-42d4-a0be-9848c9d09d4a",
   "metadata": {
    "language": "python",
    "name": "compute_shap_vals",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "#create a sample of 1000 records\ntest_pd_sample=test_pd.rename(columns=rename_dict).sample(n=2500, random_state = 100).reset_index(drop=True)\n\n#Compute shapley values for each model\nbase_shap_pd = mv_base.run(test_pd_sample, function_name=\"explain\")\nopt_shap_pd = mv_opt.run(test_pd_sample, function_name=\"explain\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f74e0dcc-a850-474a-b475-f05a77619731",
   "metadata": {
    "language": "python",
    "name": "base_shap_summary_plot",
    "resultHeight": 571,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import shap \n\nshap.summary_plot(np.array(base_shap_pd.astype(float)), \n                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67469a84-3d44-49e4-8d6e-5cd8a6e8a633",
   "metadata": {
    "language": "python",
    "name": "opt_shap_summary_plot"
   },
   "outputs": [],
   "source": "shap.summary_plot(np.array(opt_shap_pd.astype(float)), \n                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3a0d4c3-750c-4ae0-9812-85b677db6986",
   "metadata": {
    "language": "python",
    "name": "create_all_shap_dfs",
    "collapsed": false
   },
   "outputs": [],
   "source": "#Merge shap vals and actual vals together for easier plotting below\nall_shap_base = test_pd_sample.merge(base_shap_pd, right_index=True, left_index=True, how='outer')\nall_shap_opt = test_pd_sample.merge(opt_shap_pd, right_index=True, left_index=True, how='outer')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "938441fd-9ae3-4f97-9a54-b7e4c74738ac",
   "metadata": {
    "language": "python",
    "name": "plot_income_explanation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\n#filter data down to strip outliers\nasb_filtered = all_shap_base[(all_shap_base.INCOME>0) & (all_shap_base.INCOME<250000)]\naso_filtered = all_shap_opt[(all_shap_opt.INCOME>0) & (all_shap_opt.INCOME<250000)]\n\n# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"INCOME EXPLANATION\")\n# Plot side-by-side boxplots\nsns.scatterplot(data = asb_filtered, x ='INCOME', y = 'INCOME_explanation', ax=axes[0])\nsns.regplot(data = asb_filtered, x =\"INCOME\", y = 'INCOME_explanation', scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[0])\n\naxes[0].set_title('Base Model')\nsns.scatterplot(data = aso_filtered, x ='INCOME', y = 'INCOME_explanation',color = \"orange\", ax = axes[1])\nsns.regplot(data = aso_filtered, x =\"INCOME\", y = 'INCOME_explanation', scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Income\")\n    ax.set_ylabel(\"Influence\")\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2298b1f8-0495-42e1-b668-0dcd03d8bb7c",
   "metadata": {
    "language": "python",
    "name": "plot_loan_amount_explanation",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#filter data down to strip outliers\nasb_filtered = all_shap_base[all_shap_base.LOAN_AMOUNT<2000000]\naso_filtered = all_shap_opt[all_shap_opt.LOAN_AMOUNT<2000000]\n\n\n# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"LOAN_AMOUNT EXPLANATION\")\n# Plot side-by-side boxplots\nsns.scatterplot(data = asb_filtered, x ='LOAN_AMOUNT', y = 'LOAN_AMOUNT_explanation', ax=axes[0])\nsns.regplot(data = asb_filtered, x =\"LOAN_AMOUNT\", y = 'LOAN_AMOUNT_explanation', scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=True, ax =axes[0])\naxes[0].set_title('Base Model')\n\nsns.scatterplot(data = aso_filtered, x ='LOAN_AMOUNT', y = 'LOAN_AMOUNT_explanation',color = \"orange\", ax = axes[1])\nsns.regplot(data = aso_filtered, x =\"LOAN_AMOUNT\", y = 'LOAN_AMOUNT_explanation', scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=True, ax =axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"LOAN_AMOUNT\")\n    ax.set_ylabel(\"Influence\")\n    # ax.set_xlim((0,10000))\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14a03aa9-1f1a-4a4e-809e-b22e438d72aa",
   "metadata": {
    "language": "python",
    "name": "plot_home_purchase_explanation",
    "resultHeight": 851,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"HOME PURCHASE LOAN EXPLANATION\")\n# Plot side-by-side boxplots\nsns.boxplot(data = all_shap_base, x ='LOAN_PURPOSE_NAME_HOME_PURCHASE', y = 'LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_PURCHASE', width=0.8, ax=axes[0])\naxes[0].set_title('Base Model')\nsns.boxplot(data = all_shap_opt, x ='LOAN_PURPOSE_NAME_HOME_PURCHASE', y = 'LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_PURCHASE', width=0.4, ax = axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Home PURCHASE Loan (1 = True)\")\n    ax.set_ylabel(\"Influence\")\n    ax.legend(loc='upper right')\n\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66ea7aad-4e48-4666-a48c-ddc39331cb1f",
   "metadata": {
    "language": "python",
    "name": "plot_home_imrprovement_explanation",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"HOME IMPROVEMENT LOAN EXPLANATION\")\n# Plot side-by-side boxplots\nsns.boxplot(data = all_shap_base, x ='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', y = 'LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', width=0.8, ax=axes[0])\naxes[0].set_title('Base Model')\nsns.boxplot(data = all_shap_opt, x ='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', y = 'LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', width=0.4, ax = axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Home Improvement Loan (1 = True)\")\n    ax.set_ylabel(\"Influence\")\n    ax.legend(loc='upper right')\n\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df7a9ccc-e785-4a82-b9e9-97fd44d5acf2",
   "metadata": {
    "name": "Monitoring_section",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Model Monitoring setup"
  },
  {
   "cell_type": "code",
   "id": "e0751bdd-6c24-4c65-9247-aa90ebc1d376",
   "metadata": {
    "language": "python",
    "name": "create_table_from_test_data",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "train.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TRAIN_{VERSION_NUM}\", mode=\"overwrite\")\ntest.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TEST_{VERSION_NUM}\", mode=\"overwrite\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aabdf2be-87f8-4556-aa42-22e4a70515e1",
   "metadata": {
    "language": "python",
    "name": "create_stage",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session.sql(\"CREATE stage IF NOT EXISTS ML_STAGE\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21b2c090-5cc8-4847-982a-fb9b5e427616",
   "metadata": {
    "language": "python",
    "name": "define_sproc",
    "collapsed": false,
    "resultHeight": 495,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake import snowpark\n\ndef demo_inference_sproc(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n\n    reg = Registry(session=session)\n    m = reg.get_model(model_name)  # Fetch the model using the registry\n    mv = m.version(modelversion)\n    \n    input_table_name=table_name\n    pred_col = f'{modelversion}_PREDICTION'\n\n    # Read the input table to a dataframe\n    df = session.table(input_table_name)\n    results = mv.run(df, function_name=\"predict\").select(\"LOAN_ID\",'\"output_feature_0\"').withColumnRenamed('\"output_feature_0\"', pred_col)\n    # 'results' is the output DataFrame with predictions\n\n    final = df.join(results, on=\"LOAN_ID\", how=\"full\")\n    # Write results back to Snowflake table\n    final.write.save_as_table(table_name, mode='overwrite',enable_schema_evolution=True)\n\n    return \"Success\"\n\n# Register the stored procedure\nsession.sproc.register(\n    func=demo_inference_sproc,\n    name=\"model_inference_sproc\",\n    replace=True,\n    is_permanent=True,\n    stage_location=\"@ML_STAGE\",\n    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n    return_type=StringType()\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da45031a-917e-4f6d-a2e4-068879791819",
   "metadata": {
    "language": "sql",
    "name": "gb_base_train_inference",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d18ea05-7d29-43a3-9baa-52509f3bb15e",
   "metadata": {
    "language": "sql",
    "name": "gb_base_test_inference",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1d2550b-46c7-4eb7-adaa-64c345711b1e",
   "metadata": {
    "language": "sql",
    "name": "gb_opt_train_inference",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{optimized_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8245f482-19e9-4961-9cb2-801bf5948d52",
   "metadata": {
    "language": "sql",
    "name": "gb_opt_test_inference",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{optimized_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec05048c-a9d1-4ef9-bf39-5333f3fb56cb",
   "metadata": {
    "language": "sql",
    "name": "see_preds",
    "resultHeight": 251,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "select TIMESTAMP, LOAN_ID, INCOME, LOAN_AMOUNT, XGB_BASE_PREDICTION, XGB_OPTIMIZED_PREDICTION, MORTGAGERESPONSE \nFROM DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}} \nlimit 20",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f6be548-47cb-4a91-92ee-a5f42c41e756",
   "metadata": {
    "language": "sql",
    "name": "create_model_monitor_base",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_BASE_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{base_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(XGB_BASE_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='1 hour'\n    AGGREGATION_WINDOW='1 day';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60965976-f17f-42bc-92ae-e43030bba54e",
   "metadata": {
    "language": "sql",
    "name": "create_model_monitor_optimized",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_OPTIMIZED_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{optimized_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(XGB_OPTIMIZED_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='12 hours'\n    AGGREGATION_WINDOW='1 day';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b78b0fc2-555d-458b-aa07-7053859539d4",
   "metadata": {
    "language": "python",
    "name": "generate_model_registry_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Click the generated link to view your model in the model regsitry and check out the model monitors!\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/data/databases/{DB}/schemas/{SCHEMA}/model/{model_name.upper()}')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "537fc658-38f4-4c9a-980b-cf40ef61a268",
   "metadata": {
    "language": "sql",
    "name": "compute_prediction_drift",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n'MORTGAGE_LENDING_BASE_MODEL_MONITOR', -- model monitor to use\n'DIFFERENCE_OF_MEANS', -- metric for computing drift\n'XGB_BASE_PREDICTION', -- comlumn to compute drift on\n'1 DAY',  -- day granularity for drift computation\nDATEADD(DAY, -90, CURRENT_DATE()), -- end date\nDATEADD(DAY, -60, CURRENT_DATE()) -- start date\n)\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b8f8d88-1ebe-4622-89ca-39bce08473d4",
   "metadata": {
    "name": "SPCS_MD",
    "collapsed": false
   },
   "source": "# SPCS Deployment setup (OPTIONAL)\n## This is disabled by default but uncommenting the below code cells will allow a user to \n\n- ### Create a new compute pool with 3 XL CPU nodes\n- ### Create a new image repository to store the container image for conatiner-based model scoring\n- ### Deploys a service on top of our existing HPO model version\n- ### Tests out inference on newly created container service\n"
  },
  {
   "cell_type": "code",
   "id": "c416a4d0-a95f-4702-9a61-26b61706eb11",
   "metadata": {
    "language": "python",
    "name": "define_spcs_vars",
    "collapsed": false
   },
   "outputs": [],
   "source": "image_repo_name = \"MORTGAGE_LENDING_IMAGE_REPO_LLM\"\ncp_name = \"MORTGAGE_LENDING_INFERENCE_CP\"\nnum_spcs_nodes = '3'\nspcs_instance_family = 'CPU_X64_L'\nservice_name = 'MORTGAGE_LENDING_PREDICTION_SERVICE'\n\ncurrent_database = session.get_current_database().replace('\"', '')\ncurrent_schema = session.get_current_schema().replace('\"', '')\nextended_image_repo_name = f\"{current_database}.{current_schema}.{image_repo_name}\"\nextended_service_name = f'{current_database}.{current_schema}.{service_name}'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e79ff8f0-e80e-4a94-8cd0-8567e4c901ce",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "session.sql(f\"show image repositories\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "448f6702-8fb2-4aac-9e54-a8673c064074",
   "metadata": {
    "language": "python",
    "name": "setup_compute_pool"
   },
   "outputs": [],
   "source": "session.sql(f\"alter compute pool if exists {cp_name} stop all\").collect()\nsession.sql(f\"drop compute pool if exists {cp_name}\").collect()\nsession.sql(f\"create compute pool {cp_name} min_nodes={num_spcs_nodes} max_nodes={num_spcs_nodes} instance_family={spcs_instance_family} auto_resume=True auto_suspend_secs=300\").collect()\nsession.sql(f\"describe compute pool {cp_name}\").show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8537738c-7e11-42ea-847d-8871ddfe0539",
   "metadata": {
    "language": "python",
    "name": "create_image_repo"
   },
   "outputs": [],
   "source": "session.sql(f\"create or replace image repository {extended_image_repo_name}\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df47725b-e9e7-4f93-bdea-9db09794bd95",
   "metadata": {
    "language": "python",
    "name": "spcs_deploy_service",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#note this may take up to 5 minutes to run\n\nmv_opt.create_service(\n    service_name=extended_service_name,\n    service_compute_pool=cp_name,\n    image_repo=extended_image_repo_name,\n    ingress_enabled=True,\n    max_instances=int(num_spcs_nodes)\n    # build_external_access_integration=\"ALLOW_ALL_INTEGRATION\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25c4f6d4-b16b-4448-bcf3-4f128ccfbe43",
   "metadata": {
    "language": "python",
    "name": "see_model_versions_with_services"
   },
   "outputs": [],
   "source": "model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\").show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f6dcb97-aa8f-467b-a939-63d1d3b70f58",
   "metadata": {
    "language": "python",
    "name": "view_services",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mv_container = model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\").default\nmv_container.list_services()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5eb9b1a-0741-4e9d-aaf4-2da26c44ffbd",
   "metadata": {
    "language": "python",
    "name": "run_SPCS_inference",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mv_container.run(test, function_name = \"predict\", service_name = \"MORTGAGE_LENDING_PREDICTION_SERVICE\").rename('\"output_feature_0\"', 'XGB_PREDICTION')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35388bca-f70f-47db-a3ef-3558dda91502",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "#Stop the service to save costs\nsession.sql(f\"alter compute pool if exists {cp_name} stop all\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "name": "conclusion",
    "resultHeight": 202,
    "collapsed": false
   },
   "source": "## Conclusion \n\n#### 🛠️ Snowflake Feature Store tracks feature definitions and maintains lineage of sources and destinations 🛠️\n#### 🚀 Snowflake Model Registry gives users a secure and flexible framework to log models, tag candidates for production, and run inference and explainability jobs 🚀\n#### 📈 ML observability in Snowflake allows users to montior model performance over time and detect model, feature, and concept drift 📈\n#### 🔮 All models logged in the Model Registry can be accessed for inference, explainability, lineage tracking, visibility and more 🔮\n",
   "id": "ce110000-1111-2222-3333-ffffff000036"
  }
 ]
}